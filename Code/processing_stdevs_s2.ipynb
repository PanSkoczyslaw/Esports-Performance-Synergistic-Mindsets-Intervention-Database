{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1107b15d-a154-43c4-845c-8e94f59a3526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neurokit2 as nk\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af176c2-6c13-413a-9b38-6047720af0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_channel(cols_template, channel):\n",
    "    '''\n",
    "    Function to modify a template of column names to adapt to each signal.\n",
    "\n",
    "    Input:\n",
    "    cols_template (list of str): A list of column names containing a placeholder \"[channel]\".\n",
    "    channel (str): The name of the channel to replace the placeholder.\n",
    "\n",
    "    Returns:\n",
    "    list of str: A list of column names with the \"[channel]\" placeholder replaced by the provided channel name.\n",
    "    '''\n",
    "    \n",
    "    return [re.sub(r\"\\[channel\\]\", channel, col) for col in cols_template]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5efdb0a-61fd-43c2-ab20-6a9e5045f05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_stdevs_s2(file_path, bunch_of_cols, filename):\n",
    "    '''\n",
    "    Function to process standard deviations of 5-minutes baselines of SBP and DBP from a CSV file.\n",
    "\n",
    "    Input:\n",
    "    file_path (str): The path to the CSV file containing the SBP and DBP data.\n",
    "    bunch_of_cols (list of lists of str): A list of lists where each sublist contains column names for SBP and DBP data.\n",
    "    filename (str): The name of the file to be used as the index for the resulting DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame with calculated standard deviations of for each minute from 5-minute baselines of SBP and DBP. \n",
    "    The index is based on the provided filename, and the columns are defined by the input `bunch_of_cols`.\n",
    "    '''\n",
    "    i = 0\n",
    "    bn_col = 0\n",
    "    df_sub = pd.read_csv(file_path)\n",
    "    marker = 201 #Entire baseline is marked as \"201\"\n",
    "                               \n",
    "    dataframes = []\n",
    "    sbp_dbp_cols = [col for sublist in bunch_of_cols for col in sublist]\n",
    "    sbp_df = pd.DataFrame(columns=sbp_dbp_cols)\n",
    "    sbp_df.loc[0] = [None] * len(sbp_dbp_cols)\n",
    "    \n",
    "    if bn_col == 0: #start with SBP\n",
    "        curr_idx = df_sub.index[df_sub['marker'] == marker] #determining the first index for the given marker in df\n",
    "            \n",
    "            \n",
    "                \n",
    "    for y in range(0, 300000, 60000): #calculations initiated from a 5-minute baseline, with minute intervals\n",
    "        sbp = statistics.stdev(df_sub[\"SBP\"].iloc[curr_idx[0]+y:curr_idx[0]+y+60000]) \n",
    "        sbp_df.iloc[0, i] = sbp #saving calculations in local df\n",
    "        i += 1 #moving to the next column\n",
    "        \n",
    "    bn_col += 1\n",
    "    \n",
    "    if bn_col == 1: #proceed to DBP\n",
    "       \n",
    "        curr_idx = df_sub.index[df_sub['marker'] == marker]\n",
    "        for y in range(0, 300000, 60000):\n",
    "            dbp = statistics.stdev(df_sub[\"DBP\"].iloc[curr_idx[0]+y:curr_idx[0]+y+60000]) \n",
    "            sbp_df.iloc[0, i] = dbp #saving calculations in local df\n",
    "            i += 1\n",
    "\n",
    "    \n",
    "    sbp_df.index = [filename.replace('.csv', '')] #saving to df with the subject's id as the index name\n",
    "    return sbp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5e2b22-9283-43ef-8001-9d7ce404bd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_sbp_db = ['ECG_Rate_mean', 'HRV_RMSSD', 'SBP', 'DBP', 'CO', 'TPR', 'wr', 'tl', 'tr']\n",
    "list_of_channels = ['SBP', 'DBP', 'marker']\n",
    "cols_template = [\"baseline_visit2_min1_[channel]_stdev\", \"baseline_visit2_min2_[channel]_stdev\", \"baseline_visit2_min3_[channel]_stdev\", \"baseline_visit2_min4_[channel]_stdev\", \"baseline_visit2_min5_[channel]_stdev\"]\n",
    "sbp_cols = replace_channel(cols_template, list_of_channels[0])\n",
    "dbp_cols = replace_channel(cols_template, list_of_channels[1])\n",
    "bunch = [sbp_cols, dbp_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae902c4-9f33-4831-a7c6-51d6239c0530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing all CSV files in the folder\n",
    "input_folder = '/home/ubuntu/eSportData/jupyter-data/VU_AMS/s2_output/'\n",
    "output_df = pd.DataFrame()\n",
    "\n",
    "for file_name in os.listdir(input_folder):  #iterating through the list with the databases of the subjects\n",
    "    if file_name.endswith('.csv'):\n",
    "        try:\n",
    "            print(file_name)\n",
    "            file_path = os.path.join(input_folder, file_name)\n",
    "            processed_df = process_stdevs_s2(file_path, bunch, file_name) #calling the function to create df with calculated standard deviations of SBP and DBP baselines\n",
    "            output_df = pd.concat([output_df, processed_df]) #adding the subject's data from the iteration to the collective df with other subjects\n",
    "        except:\n",
    "            pass\n",
    "# Saving the resulting DataFrame to a CSV file\n",
    "output_df.to_csv('/home/ubuntu/eSportData/jupyter-data/VU_AMS/processed_stdevs_s2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
